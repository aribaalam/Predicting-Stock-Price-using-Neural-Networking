# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15WVPMWbweAaBJA7LR-UtCSFvh-DquBhE
"""

import math
import pandas_datareader as web
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

df = web.DataReader('AAPL', data_source='yahoo', start='2012-01-01', end='2019-12-17')
df

#We will get the number of rows and columns in the dataset

df.shape

#We will see the closing price history

plt.figure(figsize=(16,8))
plt.title('Close Price History')
plt.plot(df['Close'])
plt.xlabel('Date', fontsize=18)
plt.ylabel('Close Price USD ($)', fontsize=18)
plt.show()

data = df.filter(['Close']) #Creating a new dataframe keeping the 'Close' column only
dataset = data.values #converting our dataframe to a numpy array
training_data_len = math.ceil(len( dataset ) *.8) #we will train on 80% of the data from dataset
training_data_len # we will get the length of our training dataset

#scaling the data (it is better to scale or normalise the data during preprocessing)
scaler =MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset) #transforms data to min and max scaling with range from 0 to 1 and anything in between
scaled_data

train_data=scaled_data[0:training_data_len , :]


x_train = []
y_train = []

for i in range(60, len(train_data)):
  x_train.append(train_data[i-60:i,0]) 
  y_train.append(train_data[i,0]) 
if i<= 61:
  print (x_train)
  print (y_train)
  print()



x_train, y_train = np.array(x_train), np.array(y_train)

#reshape x train dataset (LSTM expects the input to be 3 dim, but our data is 2 dim)


x_train= np.reshape (x_train, (x_train.shape[0], x_train.shape[1] , 1))
x_train.shape

#building LSTM model

model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1],1)))
model.add(LSTM(50, return_sequences= False))
model.add(Dense(25))
model.add(Dense(1))

#Compiling the model

model.compile(optimizer='adam', loss='mean_squared_error') # the loss function will see how well the model did on training
model.fit(x_train, y_train, batch_size=1, epochs=1) #epoch(number of iterations back and forth)

#lets create testing dataset now

#new array containing scaled values from index 1543 to 2003

test_data = scaled_data[training_data_len - 60: , :]
#creating data sets xtest and ytest

x_test = []
y_test = dataset[training_data_len: , :] #values we want our model to predict

for i in range(60 , len(test_data)):
  x_test.append(test_data[i-60:i, 0])

#converting data into numpy array to use it in LSTM model

x_test = np.array(x_test)

#reshaping the data to 3D for LSTM

x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1] , 1))

#Gett the models predicted price values

predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions) #unscaling values

#getting root mean squared error (RMSE), we will evaluate our model, how well it performs

rmse = np.sqrt(np.mean(predictions - y_test )**2)
rmse

#plotting data

train = data[:training_data_len]
valid = data[training_data_len:]
valid['Predictions']= predictions
#visualising the data

plt.figure(figsize=(16,8))
plt.title('Model')
plt.xlabel('Date',fontsize=18)
plt.ylabel('Close Price USD($)',fontsize=18)
plt.plot(train['Close'])
plt.plot(valid[['Close', 'Predictions']])
plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')
plt.show()

valid

apple_quote= web.DataReader('AAPL', data_source ='yahoo', start='2012-01-01', end='2019-12-17')
new_df=apple_quote.filter(['Close'])
last_60_days = new_df[-60:].values #getting last 60 values and converting to array
last_60_days_scaled = scaler.transform(last_60_days)
#creating an empty list

X_test= []
#appending past 60 days

X_test.append(last_60_days_scaled)
#converting x_test to a numpy array

X_test = np.array(X_test)
#Reshaping the data

X_test=np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
#get predicted scaled price

pred_price = model.predict(X_test)
#undo scaling

pred_price=scaler.inverse_transform(pred_price)
print(pred_price)

apple_quote2= web.DataReader('AAPL', data_source ='yahoo', start='2019-12-30', end='2019-12-30')
print(apple_quote2['Close'])